![Alt text](Assets/4..png)

# Tokenomics Documentation: Fair Pricing and Distribution Model

## Overview

CognideX's Tokenomics is designed to incentivize the fair monetization of data contributions while maintaining a balanced and reasonable marketplace. This document outlines token distribution, burning strategies and procedures for setting data prices, aggregating contributions, determining the final sale price, and distributing proceeds among contributors.

## Token Distribution and Burning Mechanism

### Token Distribution

A total supply of 100 million CGDX tokens will be made available and distributed among developers and users, with a certain portion kept as reserves. The distribution proposal is as follows:

1. **ICO**: 10% of the supply is kept for conducting the Initial Coin Offering.

2. **Developer Team**: 15% of total supply is allocated to the developer team. The tokens will be dispersed at a rate of 20%/year, i.e. a vesting period of 5 years, thus promoting a long-term commitment.

3. **Community Incentives**: 35% of the total supply is available for user rewards, staking, and community engagement programs.

4. **Marketing & Ecosystem Development**: 20% of total supply will be kept as reserves as a means of carrying out partnerships, advertising/marketing and community building.

5. **Company Reserves**: 20% of total supply is kept as company’s reserve to tackle unforeseen expenses.

### Burning Mechanism
The following burning mechanisms are devised to help control market flooding and sudden drop of token value.

1. **Transaction Fee**: A transaction fee is implemented (around 0.5-1%) on each transaction to help reduce the total supply of tokens in the market, helping in increasing the scarcity of tokens.

2. **Buy Back**: Tokens can be bought back using the company’s revenue/profits in case the token price falls by more than 20% in a short period. This will help control market flooding and reduce token supply, potentially increasing the token’s value over time.

3. **Lottery Mechanism**: Conducting regular lotteries on the platform with an entry fee of 10-20 tokens. Winners will be chosen randomly and awarded a portion of the lottery collected. Some portion will be burned to help increase scarcity of tokens.


## Data Contribution and Preliminary Valuation

Contributors upload their datasets to the platform, setting their desired price tags based on personal valuation. An approved analyst then aggregates these datasets and performs a detailed analysis to suggest a bundled value for the insights derived from the collective data.

(Note: The examples are completely hypothetical. We need to replace all with real Tokenomics.)

## Establishing Price Reasonability

To ensure that the final price suggested by analysts remains within a reasonable range:

1. **Maximum Price Cap:** A cap is implemented based on:
   - Median contributor price.
   - Historical sales data.
   - Total number of contributions.

2. **Weighted Average Pricing:** 
   - A baseline price per unit of data (e.g., per MB) is calculated using a weighted average that considers dataset size and quality score.

## Community Voting for Final Price

A community-driven voting round is initiated to gather consensus on the final value of the aggregated dataset. Stakeholders cast votes that are weighted by their contribution size and quality scores. The final sale price is set by a weighted median of these votes.

## Proceeds Distribution Model

Upon the successful sale of the aggregated dataset, proceeds are allocated as follows:

1. **Contributor Earnings:** Contributors are remunerated based on their proportional share of the total data pool, adjusted by the weighted average price.

2. **Analyst Reward:** The analyst is compensated with a percentage of the total sale, capped to prevent any disproportionate allocation.

3. **Platform Sustainability:** A platform fee is deducted to support operational costs and the continuous improvement of the ecosystem.

## Example Case

With a total of 10,000MB contributed and an initial combined price tag of 100,000 Dots, the process unfolds as follows:

1. **Weighted Average Calculation:**
   - The weighted average is computed as 10 Dots/MB, setting the stage for a reasonable price range.

2. **Price Adjustment:**
   - The analyst's suggested price is adjusted to the reasonable range's upper limit if necessary.

3. **Community Consensus:**
   - Voting within the reasonable range leads to a final sale price that reflects the community's consensus.

4. **Final Distribution:**
   - The proceeds are distributed equitably among contributors and the analyst according to the established model.

## Governance and Future Adjustments

The tokenomics model is dynamic and governed by community consensus. Changes to the price cap, the weighted average mechanism, and the distribution formula can be proposed and voted upon by token holders, ensuring that the platform evolves with the needs of its users.

---

## Tokenomics Example with Markdown Formulas

### Data Listing

- **Alice** lists 20MB of Netflix data at `10 Dots`.
- **Bob** lists 3MB of Netflix data at `10,000 Dots` (outlier).
- **Carl** lists 200MB of Netflix data at `10 Dots`.
- **Dimitry** lists 10MB of Netflix data at `20 Dots`.
- (Assuming a total of `1004` contributors, contributing a total of `10,000MB`.)

### Analyst's Aggregated Valuation

- **Eve**, the data analyst, aggregates all data and proposes a valuation of `50,000 Dots` for the entire dataset.

### Reasonable Price Range Establishment

- A maximum price cap is determined at `10 Dots/MB` based on historical data and median pricing.
- The weighted average price per MB is calculated to be `7 Dots/MB`.

### Community Voting

- The community participates in voting on the final price of the dataset within the reasonable range.

### Final Price Determination

- The weighted median price after community voting is established at `9 Dots/MB`.

### Sale and Distribution of Proceeds

- The dataset is sold at the price of `9 Dots/MB`.
- Total Sale Amount: `10,000MB * 9 Dots/MB = 90,000 Dots`.

### Proceeds Distribution

- **Platform Fee**: `10%` of the total sale amount.
- **Net Proceeds for Distribution**: `85%` of the total sale amount.
- **Analyst Rewards**: `5%` of the total sale amount.

### Contributors' Earnings Calculation

- Alice's share: `(20MB / 10,000MB) * 76,500 Dots = 153 Dots`.
- Carl's share: `(200MB / 10,000MB) * 76,500 Dots = 1,530 Dots`.
- Dimitry's share: `(10MB / 10,000MB) * 76,500 Dots = 76.5 Dots`.
- (Calculated proportionally for all other contributors.)

### Analyst Reward

- Eve's reward: `5%` of the total sale amount.
- Eve's reward calculation: `90,000 Dots * 5% = 4,500 Dots`.

### Governance and Adjustments

Contributors and token holders can vote on proposals to adjust the tokenomics model.

You can check the governance future proposal in [the following page](6-Governance.md) ⬅️


